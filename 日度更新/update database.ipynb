{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d554bf0d-d02c-4065-8956-97517a3cb2a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(datetime.datetime(2024, 4, 14, 15, 30, 47),)\n",
      "Bitcoin_data\n",
      "ads\n",
      "bitcoin_test1\n",
      "bitcoin_wxc\n",
      "dwd\n",
      "dws\n",
      "information_schema\n",
      "mysql\n",
      "ods\n",
      "performance_schema\n",
      "sys\n"
     ]
    }
   ],
   "source": [
    "from google.cloud.sql.connector import Connector, IPTypes\n",
    "import sqlalchemy\n",
    "from google.oauth2 import service_account\n",
    "from sqlalchemy import text\n",
    "#pip install cloud-sql-python-connector\n",
    "\n",
    "# 指定服务账户文件路径\n",
    "SERVICE_ACCOUNT_FILE = './qf5214_lyj.json'\n",
    "                                                            #各自修改成自己的密钥文件\n",
    "# 创建服务账户凭据\n",
    "credentials = service_account.Credentials.from_service_account_file(\n",
    "    SERVICE_ACCOUNT_FILE\n",
    ")\n",
    "\n",
    "# 初始化Connector对象\n",
    "connector = Connector(credentials=credentials)\n",
    "\n",
    "def getconn() -> sqlalchemy.engine.base.Connection:\n",
    "    # 连接信息\n",
    "    instance_connection_string = \"supple-folder-418707:us-central1:qf5214project\"\n",
    "    db_user = \"user_wxc\"\n",
    "    db_pass = \"5214group4_cloud_wxc\"\n",
    "    db_name = \"ods\"                                       # 替换为你的实际数据库名，不过没有好像也可以\n",
    "\n",
    "    conn = connector.connect(\n",
    "        instance_connection_string,\n",
    "        \"pymysql\",  \n",
    "        user=db_user,\n",
    "        password=db_pass,\n",
    "        db=db_name,\n",
    "        ip_type=IPTypes.PUBLIC,  # 使用公共IP进行访问\n",
    "    )\n",
    "    return conn\n",
    "\n",
    "# 创建SQLAlchemy engine\n",
    "engine = sqlalchemy.create_engine(\n",
    "    \"mysql+pymysql://\",  # 我们的数据库是MySQL8.0\n",
    "    creator=getconn,\n",
    ")\n",
    "\n",
    "# 使用engine进行数据库操作\n",
    "with engine.connect() as conn:\n",
    "    result = conn.execute(text(\"SELECT NOW();\"))  # 使用text()包裹原始SQL语句，否则报错\n",
    "    for row in result:\n",
    "        print(row)      #返回数据库时间\n",
    "\n",
    "\n",
    "with engine.connect() as conn:\n",
    "    # 执行查询以获取所有数据库的列表（MySQL版本）\n",
    "    result = conn.execute(text(\"SHOW DATABASES;\"))\n",
    "    # 遍历结果并打印每个数据库名称\n",
    "    for row in result:\n",
    "        print(row[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6752e49e-eeba-4909-ac6c-064a7df5d87a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ods_market_btc_delta\n",
      "ods_market_cpi_delta\n",
      "ods_market_employment_delta\n",
      "ods_market_eth_delta\n",
      "ods_market_ffr_delta\n",
      "ods_market_sofr_delta\n",
      "ods_news_delta\n",
      "ods_talk_comments_delta\n",
      "ods_talk_subjects_delta\n",
      "ods_talk_users_delta\n"
     ]
    }
   ],
   "source": [
    "conn = engine.connect()\n",
    "\n",
    "# 执行查询以获取所有数据库的列表（MySQL版本）\n",
    "conn.execute(text(\"use ods;\"))\n",
    "#conn.execute(text(\"drop table if exists news;\"))\n",
    "\n",
    "#conn.execute(text(create_table))\n",
    "#conn.execute(text(load_csv))\n",
    "#result = conn.execute(text(\"select * from news LIMIT 10;\"))\n",
    "result = conn.execute(text(\"show tables;\"))\n",
    "for row in result:\n",
    "    print(row[0])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "14d86114-a004-4a7a-8f72-d4c2c1fa38b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('date', 'date', 'NO', 'PRI', None, '')\n",
      "('employment_nonfarm', 'int', 'YES', '', None, '')\n",
      "('population', 'int', 'YES', '', None, '')\n",
      "('employment_nonfarm_ratio', 'double', 'YES', '', None, '')\n"
     ]
    }
   ],
   "source": [
    "command = conn.execute(text(\"DESCRIBE ods_market_employment_delta;\"))\n",
    "for row in command:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c6f1258-62e5-47e0-b042-83246373ef47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(datetime.date(2024, 4, 14), Decimal('64211.1661'), Decimal('61507240157.9903'))\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "def fetch_bitcoin_price(date=None):\n",
    "    if date is None:\n",
    "        date = datetime.utcnow().strftime('%Y-%m-%d')  # 使用UTC时间\n",
    "\n",
    "    # 设定当天的开始和结束时间戳\n",
    "    start_of_day = datetime.strptime(date, \"%Y-%m-%d\")\n",
    "    end_of_day = start_of_day + timedelta(days=1) - timedelta(seconds=1)  # 当天的23:59:59\n",
    "\n",
    "    url = 'https://api.coingecko.com/api/v3/coins/bitcoin/market_chart/range'\n",
    "    params = {\n",
    "        'vs_currency': 'usd',\n",
    "        'from': int(start_of_day.timestamp()),\n",
    "        'to': int(end_of_day.timestamp())\n",
    "    }\n",
    "    response = requests.get(url, params=params)\n",
    "    data = response.json()\n",
    "    \n",
    "    # 检查价格数据并返回当天最后一条记录的价格\n",
    "    if 'prices' in data and data['prices']:\n",
    "        return data['prices'][-1][1]  # 返回最后一条价格数据\n",
    "    else:\n",
    "        return None\n",
    "        \n",
    "def fetch_bitcoin_volume(date=None):\n",
    "    if date is None:\n",
    "        date = datetime.utcnow().strftime('%Y-%m-%d')  # 使用UTC时间\n",
    "\n",
    "    # 设定当天的开始和结束时间戳\n",
    "    start_of_day = datetime.strptime(date, \"%Y-%m-%d\")\n",
    "    end_of_day = start_of_day + timedelta(days=1) - timedelta(seconds=1)  # 当天的23:59:59\n",
    "\n",
    "    url = 'https://api.coingecko.com/api/v3/coins/bitcoin/market_chart/range'\n",
    "    params = {\n",
    "        'vs_currency': 'usd',\n",
    "        'from': int(start_of_day.timestamp()),\n",
    "        'to': int(end_of_day.timestamp())\n",
    "    }\n",
    "    response = requests.get(url, params=params)\n",
    "    data = response.json()\n",
    "    \n",
    "    # 检查交易量数据并返回当天最后一条记录的交易量\n",
    "    if 'total_volumes' in data and data['total_volumes']:\n",
    "        return data['total_volumes'][-1][1]  # 返回最后一条交易量数据\n",
    "    else:\n",
    "        return None\n",
    "        \n",
    "price = fetch_bitcoin_price()\n",
    "volume = fetch_bitcoin_volume()\n",
    "\n",
    "current_date = datetime.utcnow().strftime('%Y-%m-%d')\n",
    "conn.execute(\n",
    "    text(\"REPLACE INTO ods_market_btc_delta (date, btc_price, btc_volume) VALUES (:date, :btc_price, :btc_volume);\"),\n",
    "    {'date': current_date, 'btc_price': price, 'btc_volume': volume}\n",
    ")\n",
    "result = conn.execute(text(\"SELECT * FROM ods_market_btc_delta ORDER BY date DESC;\"))\n",
    "for row in result:\n",
    "    print(row)\n",
    "#fetch_bitcoin_price()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "be211484-13e4-4466-9e60-2dc128935eb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(datetime.date(2024, 4, 14), None)\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "def cpi_function(date=None, api_key='7de51df1d77defbeae082211557f4d6a'):\n",
    "    if date is None:\n",
    "        current_date = pd.Timestamp.today()\n",
    "\n",
    "    cpi_series_id = 'CPIAUCNS'  # CPI All Urban Consumers\n",
    "    \n",
    "    while True:\n",
    "        date = current_date.strftime('%Y-%m-%d')\n",
    "        \n",
    "        cpi_api_url = f'https://api.stlouisfed.org/fred/series/observations?series_id={cpi_series_id}&api_key={api_key}&file_type=json&observation_start={date}&observation_end={date}'\n",
    "        cpi_response = requests.get(cpi_api_url)\n",
    "        cpi_response.raise_for_status()  # Raise an exception for 4xx or 5xx status codes\n",
    "        cpi_data = cpi_response.json()\n",
    "    \n",
    "        # Check if observations are available\n",
    "        if 'observations' not in cpi_data or not cpi_data['observations']:\n",
    "            current_date -= timedelta(days = 1)  # No data available for the specified date, move to the previous day\n",
    "            continue\n",
    "        else:\n",
    "            cpi_value = cpi_data['observations'][0]['value']\n",
    "        return float(cpi_value), date\n",
    "\n",
    "cpi_update, valid_date= cpi_function()\n",
    "current_date = pd.Timestamp.today().strftime('%Y-%m-%d')\n",
    "if valid_date == current_date:\n",
    "    conn.execute(\n",
    "        text(\"REPLACE INTO ods_market_cpi_delta (date, cpi) VALUES (:date, :cpi);\"),\n",
    "        {'date': valid_date, 'cpi': cpi_update}\n",
    "    )\n",
    "else:\n",
    "    conn.execute(\n",
    "        text(\"REPLACE INTO ods_market_cpi_delta (date, cpi) VALUES (:date, :cpi);\"),\n",
    "        {'date': current_date, 'cpi': None}\n",
    "    )\n",
    "result = conn.execute(text(\"SELECT * FROM ods_market_cpi_delta ORDER BY date DESC;\"))\n",
    "for row in result:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "89f2871d-4de7-4185-899d-aeaffd6c6ca1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(datetime.date(2024, 4, 14), None, None, None)\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import timedelta\n",
    "\n",
    "def non_farmer_function(date=None, api_key='7de51df1d77defbeae082211557f4d6a'):\n",
    "    if date is None:\n",
    "        current_date = pd.Timestamp.today()\n",
    "\n",
    "    population_series_id = 'POPTHM'  # Total Population\n",
    "    payems_series_id = 'PAYEMS'  # Nonfarm Payroll Employment\n",
    "\n",
    "    # Fetch population data\n",
    "    while True:\n",
    "        date = current_date.strftime('%Y-%m-%d')\n",
    "        \n",
    "        population_api_url = f'https://api.stlouisfed.org/fred/series/observations?series_id={population_series_id}&api_key={api_key}&file_type=json&observation_start={date}&observation_end={date}'\n",
    "        population_response = requests.get(population_api_url)\n",
    "        population_data = population_response.json()\n",
    "    \n",
    "        # Check if observations are available\n",
    "        if 'observations' not in population_data or not population_data['observations']:\n",
    "            current_date -= timedelta(days = 1)  # No data available for the specified date, move to the previous day\n",
    "            continue\n",
    "        else:\n",
    "            total_population = float(population_data['observations'][0]['value'])\n",
    "    \n",
    "        # Fetch nonfarm employment data\n",
    "        payems_api_url = f'https://api.stlouisfed.org/fred/series/observations?series_id={payems_series_id}&api_key={api_key}&file_type=json&observation_start={date}&observation_end={date}'\n",
    "        payems_response = requests.get(payems_api_url)\n",
    "        payems_data = payems_response.json()\n",
    "        \n",
    "        # Check if observations are available\n",
    "        if 'observations' not in payems_data or not payems_data['observations']:\n",
    "            current_date -= timedelta(days = 1)  # No data available for the specified date, move to the previous day\n",
    "            continue        \n",
    "        else:\n",
    "            nonfarm_employment = float(payems_data['observations'][0]['value'])\n",
    "\n",
    "        # Calculate nonfarm population ratio\n",
    "        nonfarm_population_ratio = nonfarm_employment / total_population\n",
    "        return nonfarm_employment, total_population, nonfarm_population_ratio, date\n",
    "    \n",
    "data = non_farmer_function()\n",
    "\n",
    "current_date = pd.Timestamp.today().strftime('%Y-%m-%d')\n",
    "if current_date == data[3]:\n",
    "    conn.execute(\n",
    "        text(\"REPLACE INTO ods_market_employment_delta (date, employment_nonfarm, population, employment_nonfarm_ratio) VALUES (:date, :employment_nonfarm, :population, :employment_nonfarm_ratio);\"),\n",
    "        {'date': data[3], 'employment_nonfarm': data[0], 'population': data[1], 'employment_nonfarm_ratio': data[2]}\n",
    "    )\n",
    "else:\n",
    "    conn.execute(\n",
    "    text(\"REPLACE INTO ods_market_employment_delta (date, employment_nonfarm, population, employment_nonfarm_ratio) VALUES (:date, :employment_nonfarm, :population, :employment_nonfarm_ratio);\"),\n",
    "        {'date': current_date, 'employment_nonfarm': None, 'population': None, 'employment_nonfarm_ratio': None}\n",
    "    )\n",
    "\n",
    "result = conn.execute(text(\"SELECT * FROM ods_market_employment_delta ORDER BY date DESC;\"))\n",
    "for row in result:\n",
    "    print(row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "33d97550-40b5-4e08-b50f-31fdf2b06328",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(datetime.date(2024, 4, 14), Decimal('64434.0620'), Decimal('55672903271.2681'))\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from datetime import datetime\n",
    "\n",
    "def get_fedfunds_data(date='', api_key='051f69ecb49f2cecf43a9ad162820cd1'):\n",
    "    # 检查日期输入，如果为空则使用当前日期\n",
    "    if not date:\n",
    "        date = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "    # 构建请求URL\n",
    "    url = \"https://api.stlouisfed.org/fred/series/observations\"\n",
    "    params = {\n",
    "        \"series_id\": \"FEDFUNDS\",\n",
    "        \"api_key\": api_key,\n",
    "        \"file_type\": \"json\",\n",
    "        \"observation_start\": date,\n",
    "        \"observation_end\": date,\n",
    "    }\n",
    "\n",
    "    # 发送GET请求\n",
    "    response = requests.get(url, params=params)\n",
    "    if response.status_code == 200:\n",
    "        json_data = response.json()\n",
    "        # 确保观测数据存在且不为空\n",
    "        if 'observations' in json_data and json_data['observations']:\n",
    "            # 提取并返回利率值\n",
    "            value = json_data['observations'][0]['value']\n",
    "            return value\n",
    "        else:\n",
    "            return None\n",
    "    else:\n",
    "        print(\"\")\n",
    "        return None\n",
    "rate = get_fedfunds_data()\n",
    "current_date = datetime.utcnow().strftime('%Y-%m-%d')\n",
    "conn.execute(\n",
    "    text(\"REPLACE INTO ods_market_ffr_delta (date, ffr) VALUES (:date, :ffr);\"),\n",
    "    {'date': current_date, 'ffr': rate}\n",
    ")\n",
    "result = conn.execute(text(\"SELECT * FROM ods_market_btc_delta ORDER BY date DESC;\"))\n",
    "for row in result:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b0e4a9ab-1e19-409f-b1e8-3c5f084e404d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(190328, datetime.date(2024, 4, 14), 'Hong Kong Approval of Bitcoin ETFs Could Ignite Pre - Halving Price Rally', 'http://www.econotimes.com/Hong-Kongs-Approval-of-Bitcoin-ETFs-Could-Ignite-Pre-Halving-Price-Rally-1675549', 'econotimes.com', 'English', 'United States', 0.0, 0.0)\n",
      "(190329, datetime.date(2024, 4, 14), 'Bitcoin Cash ( BCH ) Achieves Market Capitalization of $10 . 43 Billion', 'https://www.wkrb13.com/2024/04/13/bitcoin-cash-bch-achieves-market-capitalization-of-10-43-billion.html', 'wkrb13.com', 'English', 'United States', 0.0, 0.0)\n",
      "(190330, datetime.date(2024, 4, 14), 'Bitcoin Cash ( BCH ) Achieves Market Capitalization of $10 . 43 Billion', 'https://www.dailypolitical.com/2024/04/13/bitcoin-cash-bch-achieves-market-capitalization-of-10-43-billion.html', 'dailypolitical.com', 'English', 'United States', 0.0, 0.0)\n",
      "(190331, datetime.date(2024, 4, 14), 'Get ready , the Bitcoin  halving  is coming', 'https://nypost.com/2024/04/13/business/get-ready-the-bitcoin-halving-is-coming/', 'nypost.com', 'English', 'United States', 0.2, 0.5)\n",
      "(190332, datetime.date(2024, 4, 14), '3 Ways Bitcoin Miners Could Make Up for Lost Revenue After the Halving', 'https://www.investopedia.com/3-ways-bitcoin-miners-could-make-up-for-lost-revenue-after-the-halving-8628609', 'investopedia.com', 'English', 'United States', 0.0, 0.0)\n",
      "(190333, datetime.date(2024, 4, 14), 'Bitcoin SV Hits Market Capitalization of $1 . 51 Billion ( BSV ) ', 'https://www.modernreaders.com/news/2024/04/13/bitcoin-sv-hits-market-capitalization-of-1-51-billion-bsv.html', 'modernreaders.com', 'English', 'United States', 0.0, 0.0)\n",
      "(190334, datetime.date(2024, 4, 14), 'Bitcoin Gold Price Hits $40 . 07 on Top Exchanges ( BTG ) ', 'https://www.themarketsdaily.com/2024/04/13/bitcoin-gold-price-hits-40-07-on-top-exchanges-btg.html', 'themarketsdaily.com', 'English', 'United States', 0.5, 0.5)\n",
      "(190335, datetime.date(2024, 4, 14), '  It Going To Zero  Legendary Billionaire Predicts  Rapid , Cataclysmic  U . S . Dollar Collapse And A $5 Trillion Post - Halving Bitcoin Price Boom', 'https://www.forbes.com/sites/digital-assets/2024/04/13/its-going-to-zero-legendary-billionaire-predicts-cataclysmic-us-dollar-collapse-and-a-post-halving-250000-bitcoin-price/', 'forbes.com', 'English', 'United States', 1.0, 1.0)\n",
      "(190336, datetime.date(2024, 4, 14), 'BITCOIN ADDITIONAL Price Up 0 % Over Last 7 Days ( BTCA ) ', 'https://www.wkrb13.com/2024/04/13/bitcoin-additional-price-up-0-over-last-7-days-btca.html', 'wkrb13.com', 'English', 'United States', 0.0, 0.06666666666666667)\n",
      "(190337, datetime.date(2024, 4, 14), 'Where Will Bitcoin Be in 5 Years ? ', 'https://finance.yahoo.com/news/where-bitcoin-5-years-102600348.html', 'finance.yahoo.com', 'English', 'United States', 0.0, 0.0)\n"
     ]
    }
   ],
   "source": [
    "#pip install gdeltdoc\n",
    "\n",
    "from gdeltdoc import GdeltDoc, Filters, repeat\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from textblob import TextBlob\n",
    "\n",
    "result_df = pd.DataFrame()\n",
    "\n",
    "\n",
    "start_date = datetime.today().date() - timedelta(days=1)\n",
    "end_date = datetime.today().date() - timedelta(days=1)\n",
    "error = list()\n",
    "\n",
    "current_date = start_date\n",
    "while current_date <= end_date:\n",
    "\n",
    "    next_date = current_date + timedelta(days=1)\n",
    "    \n",
    "    current_date_str = current_date.strftime('%Y-%m-%d')\n",
    "    next_date_str = next_date.strftime('%Y-%m-%d')\n",
    "    \n",
    "    f = Filters(\n",
    "        keyword = \"bitcoin\",\n",
    "        start_date = current_date_str,\n",
    "        end_date =  next_date_str,\n",
    "        num_records = 250,\n",
    "        \n",
    "        \n",
    "        #domain = [\"bbc.co.uk\", \"nytimes.com\", \"yahoo.com\", \"newsbtc.com\", \"coindesk.com\",\n",
    "        #          \"twitter.com\", \"medium.com\", \"bitcoinmagazine.com\", \"reddit.com\"],\n",
    "        \n",
    "        \n",
    "        country = [\"US\", \"UK\", \"CN\", \"JA\", \"GM\"],\n",
    "        repeat = repeat(5, \"bitcoin\")\n",
    "    )\n",
    "\n",
    "    gd = GdeltDoc()\n",
    "    try:\n",
    "        articles = gd.article_search(f)\n",
    "    except Exception as e:\n",
    "        print('导出异常，跳过！！')\n",
    "        error.append(current_date)\n",
    "        current_date = next_date\n",
    "        continue\n",
    "    #timeline = gd.timeline_search(\"timelinevol\", f)\n",
    "    \n",
    "    result_df = pd.concat([result_df, articles], ignore_index=True)\n",
    "    \n",
    "    # 将日期向前推进一天\n",
    "    current_date = next_date\n",
    "    \n",
    "result_df = result_df.drop_duplicates()\n",
    "\n",
    "#bitcoin_20170101_20170630_big = r'C:\\Users\\User\\Desktop\\2024_2.xlsx'\n",
    "#result_df.to_excel(bitcoin_20170101_20170630_big, sheet_name=\"Sheet1\", index=False)\n",
    "columns_to_keep = ['url', 'title', 'domain', 'language', 'sourcecountry']\n",
    "valid_df = result_df[columns_to_keep]\n",
    "new_column_names = {\n",
    "    'url': 'news_url',\n",
    "    'title': 'news_title',\n",
    "    'domain': 'news_domain',\n",
    "    'language': 'news_language',\n",
    "    'sourcecountry': 'news_country'\n",
    "}\n",
    "\n",
    "# 重命名列\n",
    "df = valid_df.rename(columns=new_column_names)\n",
    "\n",
    "def sentiment_polarity(text):\n",
    "    if pd.isna(text):\n",
    "        return 0.0\n",
    "    return TextBlob(text).sentiment.polarity\n",
    "\n",
    "def sentiment_subjectivity(text):\n",
    "    if pd.isna(text):\n",
    "        return 0.5\n",
    "    return TextBlob(text).sentiment.subjectivity\n",
    "\n",
    "# Apply the sentiment analysis functions to the 'title' column\n",
    "df['news_title_emotion'] = df['news_title'].apply(sentiment_polarity)\n",
    "df['news_title_subjectivity'] = df['news_title'].apply(sentiment_subjectivity)\n",
    "\n",
    "\n",
    "result = conn.execute(text(\"SELECT COUNT(news_id) FROM dwd.dwd_news_df;\"))\n",
    "for i in result:\n",
    "    news_number = i[0]\n",
    "    \n",
    "df = df.reset_index()\n",
    "df['news_id'] = df['index'] + news_number + 1\n",
    "df.drop('index', axis=1, inplace=True)\n",
    "current_date = datetime.now().strftime('%Y-%m-%d')\n",
    "df['date'] = current_date\n",
    "\n",
    "correct_column_order = [\n",
    "    'news_id', 'date', 'news_title', 'news_url', 'news_domain', \n",
    "    'news_language', 'news_country', 'news_title_emotion', 'news_title_subjectivity'\n",
    "]\n",
    "\n",
    "df = df[correct_column_order]\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    command = f\"\"\"REPLACE INTO ods_news_delta (news_id, date, news_title, news_url, news_domain, news_language, news_country, news_title_emotion, news_title_subjectivity) \n",
    "    VALUES ('{row['news_id']}', '{row['date']}', '{row['news_title']}', '{row['news_url']}', '{row['news_domain']}', \n",
    "    '{row['news_language']}', '{row['news_country']}', '{row['news_title_emotion']}','{row['news_title_subjectivity']}');\"\"\"\n",
    "    conn.execute(text(command))\n",
    "result = conn.execute(text(\"SELECT * FROM ods_news_delta LIMIT 10;\"))\n",
    "for row in result:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "66e81549-ff24-4f6a-a6ed-5e60b5ff529d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(datetime.date(2024, 4, 14), Decimal('5.3300'))\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "\n",
    "def get_sofr_data(date=None, api_key='051f69ecb49f2cecf43a9ad162820cd1'):\n",
    "    \n",
    "    date = pd.Timestamp.today().strftime(\"%Y-%m-%d\")\n",
    "    # 构建请求URL\n",
    "    url = f\"https://api.stlouisfed.org/fred/series/observations\"\n",
    "    params = {\n",
    "        \"series_id\": \"FEDFUNDS\",\n",
    "        \"api_key\": api_key,\n",
    "        \"file_type\": \"json\",\n",
    "        \"observation_start\": date,\n",
    "        \"observation_end\": date,\n",
    "    }\n",
    "\n",
    "    # 发送GET请求\n",
    "    response = requests.get(url, params=params)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        json_data = response.json()\n",
    "        if 'observations' in json_data:\n",
    "            # 获取数据\n",
    "            try:\n",
    "                value = json_data['observations'][0]['value']\n",
    "            except Exception as e:\n",
    "                date = pd.to_datetime(date) - timedelta(days=30)\n",
    "                date = str(date)[0:10]\n",
    "                url = f\"https://api.stlouisfed.org/fred/series/observations\"\n",
    "                params = {\n",
    "                    \"series_id\": \"FEDFUNDS\",\n",
    "                    \"api_key\": api_key,\n",
    "                    \"file_type\": \"json\",\n",
    "                    \"observation_start\": date,\n",
    "                    \"observation_end\": date,\n",
    "                }\n",
    "                response = requests.get(url, params=params)\n",
    "                json_data = response.json()\n",
    "                if 'observations' in json_data:\n",
    "                    value = json_data['observations'][0]['value']\n",
    "                else:\n",
    "                    return None\n",
    "            return value\n",
    "        else:\n",
    "            return None\n",
    "    else:\n",
    "        print(f\"Failed to retrieve interest rate data for {date}, status code: {response.status_code}\")\n",
    "        return None\n",
    "rate = get_sofr_data()\n",
    "current_date = pd.Timestamp.today().strftime(\"%Y-%m-%d\")\n",
    "conn.execute(\n",
    "    text(\"REPLACE INTO ods_market_sofr_delta (date, sofr) VALUES (:date, :sofr);\"),\n",
    "    {'date': current_date, 'sofr': rate}\n",
    ")\n",
    "result = conn.execute(text(\"SELECT * FROM ods_market_sofr_delta ORDER BY date DESC;\"))\n",
    "for row in result:\n",
    "    print(row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3bbf933e-2359-413e-84f9-755620c3bf0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "import pandas as pd\n",
    "import time\n",
    "from datetime import date,timedelta,datetime\n",
    "import re\n",
    "import os\n",
    "\n",
    "def getComment(driver,formatted_date):\n",
    "    pagenow = 1\n",
    "    comment = []\n",
    "    flag = True\n",
    "    users = []\n",
    "    dates = []\n",
    "    acts = []\n",
    "    merit = []\n",
    "    while flag == True:\n",
    "        dt = driver.find_elements(By.XPATH,\"//tbody//tr//td[@valign='middle']//div[@class='smalltext']\")\n",
    "        content = driver.find_elements(By.XPATH,\"//td[@class='td_headerandpost']//div[@class='post']\")\n",
    "        user = driver.find_elements(By.XPATH,\"//td[@class='poster_info']//b//a\")\n",
    "        act = driver.find_elements(By.XPATH,\"//td[@class='poster_info']//div[@class='smalltext']\")\n",
    "        content_list = []\n",
    "        dt_list = []\n",
    "        user_list = []\n",
    "        act_list = []\n",
    "        for i in range(min(len(content),len(user),len(act))):\n",
    "            content_list.append(content[i].get_attribute('textContent'))\n",
    "            user_list.append(user[i].get_attribute('textContent'))\n",
    "            act_list.append(act[i].get_attribute('textContent'))\n",
    "        for j in range(len(dt)):\n",
    "            dt_list.append(dt[j].get_attribute('textContent'))\n",
    "        indexes_to_remove2 = [index for index, item in enumerate(dt_list) if item.startswith('Merited')]\n",
    "        for index2 in sorted(indexes_to_remove2, reverse=True):\n",
    "            del dt_list[index2]\n",
    "        indexes_to_remove = [index for index, item in enumerate(dt_list) if item[0].isdigit()]\n",
    "        for index in sorted(indexes_to_remove, reverse=True):\n",
    "            del content_list[index]\n",
    "            del dt_list[index]\n",
    "            del act_list[index]\n",
    "            del user_list[index]\n",
    "        \n",
    "        for z in range(min(len(dt_list),len(user_list),len(content_list),len(act_list))):\n",
    "            comment.append(content_list[z])\n",
    "            users.append(user_list[z])\n",
    "            dates.append(dt_list[z])\n",
    "            match1 = re.search(r'Activity: (\\d+)', act_list[z])\n",
    "            activity_number = match1.group(1) if match1 else None\n",
    "            acts.append(activity_number)\n",
    "            match2 = re.search(r'Merit: (\\d+)', act_list[z])\n",
    "            merit_number = match2.group(1) if match2 else None\n",
    "            merit.append(merit_number)\n",
    "        page = driver.find_elements(By.XPATH,\"//a[@class='navPages']\")\n",
    "        for k in range(len(page)):\n",
    "            try:\n",
    "                value = int(page[k].get_attribute('textContent'))\n",
    "            except:\n",
    "                value = 0\n",
    "            if value == pagenow + 1:\n",
    "                pagenow = pagenow+1\n",
    "                page[k].click()\n",
    "                time.sleep(2)\n",
    "                break\n",
    "        else:\n",
    "            flag = False\n",
    "    dates_to_remain = [index for index, item in enumerate(dates) if item.startswith('T')]\n",
    "    comment = [comment[a] for a in dates_to_remain if a<len(comment)]\n",
    "    dates = [dates[b] for b in dates_to_remain if b<len(dates)]\n",
    "    users = [users[c] for c in dates_to_remain if c<len(users)]\n",
    "    acts = [acts[d] for d in dates_to_remain if d<len(acts)]\n",
    "    merit = [merit[e] for e in dates_to_remain if e<len(merit)]\n",
    "    for w in range(len(dates)):\n",
    "        if dates[w].startswith('T'):\n",
    "            dates[w]  = formatted_date\n",
    "    return comment,dates,users,acts,merit\n",
    "def commentToday():\n",
    "    path = r'./chromedriver.exe'\n",
    "    cService = webdriver.ChromeService(executable_path=r'./chromedriver.exe')\n",
    "    opt = Options()\n",
    "    opt.add_argument(\"--headless\") \n",
    "    driver = webdriver.Chrome(service = cService,options=opt)\n",
    "    url = 'https://bitcointalk.org/index.php?board=1.0'\n",
    "    driver.get(url)\n",
    "    current_date = datetime.now()\n",
    "    formatted_date = current_date.strftime('%B %d, %Y')\n",
    "    df = pd.DataFrame(columns=['subject','replies','views','comment','date','user','activity','merit'])\n",
    "    a = driver.find_elements(By.XPATH,\"//td[@class='windowbg']//span/a\")\n",
    "    b = driver.find_elements(By.XPATH, \"//td[@class='windowbg' and @valign='middle' and @width='4%' and @align='center']\")\n",
    "    c = driver.find_elements(By.XPATH, \"//td[contains(@class, 'windowbg2') and contains(@class, 'lastpostcol')]//span[@class='smalltext']\")\n",
    "    url_list = []\n",
    "    sub_list = []\n",
    "    rep_list = []\n",
    "    view_list = []\n",
    "    date_list = []\n",
    "    for j in range(min(len(a),len(b)//2)):\n",
    "        url_list.append(a[j].get_attribute('href'))\n",
    "        sub_list.append(a[j].get_attribute('textContent'))\n",
    "        v1 = b[2*j].get_attribute('textContent').replace('\\n', '').replace('\\t', '')\n",
    "        v2 = b[2*j+1].get_attribute('textContent').replace('\\n', '').replace('\\t', '')\n",
    "        d1 = c[j].get_attribute('textContent').replace('\\n', '').replace('\\t', '')\n",
    "        rep_list.append(v1)\n",
    "        view_list.append(v2)\n",
    "        date_list.append(d1)\n",
    "\n",
    "    post_to_view = [index for index, item in enumerate(date_list) if item.startswith('T')]\n",
    "    url_list = [url_list[k] for k in post_to_view if k<len(url_list)]\n",
    "\n",
    "    for z in range(len(url_list)):\n",
    "        current_url = driver.current_url\n",
    "        driver.get(url_list[z])\n",
    "        c,d,u,a,m = getComment(driver,formatted_date)\n",
    "        for i in range(len(c)):\n",
    "            ct = [sub_list[z],rep_list[z],view_list[z],c[i],d[i],u[i],a[i],m[i]]\n",
    "            ctm = pd.DataFrame(ct).T\n",
    "            ctm.columns=['subject','replies','views','comment','date','user','activity','merit']\n",
    "            df = pd.concat([df,ctm])\n",
    "\n",
    "        df = df.reset_index(drop=True)\n",
    "        time.sleep(3)\n",
    "        driver.get(current_url) \n",
    "    df_subject = df.drop_duplicates(subset=['subject'])[['subject','replies', 'views']]\n",
    "    df_comment = df[['subject','comment','date','user']]\n",
    "    df_user = df.drop_duplicates(subset=['user'])[['user','activity', 'merit']]\n",
    "    return df_subject,df_comment,df_user\n",
    "df_subject,df_comment,df_user = commentToday()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6380be33-d2ae-4469-89d0-45092ac83842",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('talk_subject_id', 'varchar(300)', 'NO', 'PRI', None, '')\n",
      "('date', 'date', 'YES', '', None, '')\n",
      "('talk_subject_replies', 'int', 'YES', '', None, '')\n",
      "('talk_subject_views', 'int', 'YES', '', None, '')\n",
      "('talk_subject_emotion', 'double', 'YES', '', None, '')\n",
      "('talk_subject_subjectivity', 'double', 'YES', '', None, '')\n"
     ]
    }
   ],
   "source": [
    "'''ods_talk_comments_delta\n",
    "ods_talk_subjects_delta\n",
    "ods_talk_users_delta'''\n",
    "command = conn.execute(text(\"describe ods_talk_subjects_delta;\"))\n",
    "for row in command:\n",
    "    print(row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6045e00e-232f-4379-9ab8-56d3b6440cc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('talk_comment_id', 'int', 'NO', 'PRI', None, '')\n",
      "('date', 'date', 'YES', '', None, '')\n",
      "('talk_subject_id', 'varchar(300)', 'YES', '', None, '')\n",
      "('talk_user_id', 'varchar(100)', 'YES', '', None, '')\n",
      "('talk_comment', 'text', 'YES', '', None, '')\n",
      "('talk_comment_emotion', 'double', 'YES', '', None, '')\n"
     ]
    }
   ],
   "source": [
    "command = conn.execute(text(\"describe ods_talk_comments_delta;\"))\n",
    "for row in command:\n",
    "    print(row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "de1673ac-920f-4432-8bc9-1193d8a339d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('talk_user_id', 'varchar(100)', 'NO', 'PRI', None, '')\n",
      "('talk_user_activity', 'int', 'YES', '', None, '')\n",
      "('talk_user_merit', 'int', 'YES', '', None, '')\n"
     ]
    }
   ],
   "source": [
    "command = conn.execute(text(\"describe ods_talk_users_delta;\"))\n",
    "for row in command:\n",
    "    print(row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2d076b99-f95c-4b55-926d-98102d06a217",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>talk_subject_id</th>\n",
       "      <th>talk_subject_replies</th>\n",
       "      <th>talk_subject_views</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bitcoin puzzle transaction ~32 BTC prize to wh...</td>\n",
       "      <td>4890</td>\n",
       "      <td>182347</td>\n",
       "      <td>2024-04-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Gold vs bitcoin in a WWIII scenario</td>\n",
       "      <td>4</td>\n",
       "      <td>17</td>\n",
       "      <td>2024-04-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Short term Investors feeling cool with the cen...</td>\n",
       "      <td>8</td>\n",
       "      <td>43</td>\n",
       "      <td>2024-04-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>bullish &amp; bearish community !!!!</td>\n",
       "      <td>4</td>\n",
       "      <td>23</td>\n",
       "      <td>2024-04-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Bitcoin = Proof of Scam ?</td>\n",
       "      <td>39</td>\n",
       "      <td>290</td>\n",
       "      <td>2024-04-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[READ] Bitcoin history from 2008 to 2016!</td>\n",
       "      <td>41</td>\n",
       "      <td>544</td>\n",
       "      <td>2024-04-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Know your facts: Fundamental differences betwe...</td>\n",
       "      <td>24</td>\n",
       "      <td>212</td>\n",
       "      <td>2024-04-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>How do you know which companies to trust? Help...</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2024-04-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>It takes the balls...</td>\n",
       "      <td>17</td>\n",
       "      <td>92</td>\n",
       "      <td>2024-04-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>Bitcoin halving countdown</td>\n",
       "      <td>39</td>\n",
       "      <td>264</td>\n",
       "      <td>2024-04-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>What is a best way of taking advantage of BTC ...</td>\n",
       "      <td>84</td>\n",
       "      <td>461</td>\n",
       "      <td>2024-04-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>Iran strikes Israel. Crypto crashing heavily...</td>\n",
       "      <td>35</td>\n",
       "      <td>235</td>\n",
       "      <td>2024-04-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>Few days to 4th Bitcoin Halving</td>\n",
       "      <td>33</td>\n",
       "      <td>155</td>\n",
       "      <td>2024-04-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>Bitcoin developer @lukedashjr's wallet was hacked</td>\n",
       "      <td>280</td>\n",
       "      <td>12636</td>\n",
       "      <td>2024-04-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>El Salvador has become the first country to ma...</td>\n",
       "      <td>2458</td>\n",
       "      <td>33941</td>\n",
       "      <td>2024-04-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>DO NOT BRAG ABOUT YOUR BITCOIN</td>\n",
       "      <td>137</td>\n",
       "      <td>1043</td>\n",
       "      <td>2024-04-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>Bitcoin to the common man.</td>\n",
       "      <td>153</td>\n",
       "      <td>867</td>\n",
       "      <td>2024-04-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>Bitcoin the HERO we never knew we needed</td>\n",
       "      <td>69</td>\n",
       "      <td>402</td>\n",
       "      <td>2024-04-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>Maybe someone knows who the address belongs to?</td>\n",
       "      <td>15</td>\n",
       "      <td>251</td>\n",
       "      <td>2024-04-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>btc purchases</td>\n",
       "      <td>55</td>\n",
       "      <td>325</td>\n",
       "      <td>2024-04-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>Blackrock ETF/Bitcoin will destroy the (new) c...</td>\n",
       "      <td>29</td>\n",
       "      <td>237</td>\n",
       "      <td>2024-04-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>Debunking the Myth of Bitcoin's Use Case</td>\n",
       "      <td>33</td>\n",
       "      <td>260</td>\n",
       "      <td>2024-04-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>An AI-powered Twitter bot predicts Bitcoin’s p...</td>\n",
       "      <td>24</td>\n",
       "      <td>248</td>\n",
       "      <td>2024-04-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>What do you think?</td>\n",
       "      <td>52</td>\n",
       "      <td>390</td>\n",
       "      <td>2024-04-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>Bitcoin Bank - Safely store your bitcoin</td>\n",
       "      <td>114</td>\n",
       "      <td>1065</td>\n",
       "      <td>2024-04-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>Hodling or selling?</td>\n",
       "      <td>108</td>\n",
       "      <td>696</td>\n",
       "      <td>2024-04-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>Excessive Bitcoin fees</td>\n",
       "      <td>111</td>\n",
       "      <td>1103</td>\n",
       "      <td>2024-04-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>A Personal Computer Mined How Many Bitcoin Per...</td>\n",
       "      <td>33</td>\n",
       "      <td>327</td>\n",
       "      <td>2024-04-14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       talk_subject_id talk_subject_replies  \\\n",
       "0    Bitcoin puzzle transaction ~32 BTC prize to wh...                 4890   \n",
       "5                  Gold vs bitcoin in a WWIII scenario                    4   \n",
       "13   Short term Investors feeling cool with the cen...                    8   \n",
       "14                    bullish & bearish community !!!!                    4   \n",
       "15                           Bitcoin = Proof of Scam ?                   39   \n",
       "16          [READ] Bitcoin history from 2008 to 2016!                    41   \n",
       "35   Know your facts: Fundamental differences betwe...                   24   \n",
       "48   How do you know which companies to trust? Help...                    0   \n",
       "50                               It takes the balls...                   17   \n",
       "81                          Bitcoin halving countdown                    39   \n",
       "104  What is a best way of taking advantage of BTC ...                   84   \n",
       "107    Iran strikes Israel. Crypto crashing heavily...                   35   \n",
       "110                   Few days to 4th Bitcoin Halving                    33   \n",
       "114  Bitcoin developer @lukedashjr's wallet was hacked                  280   \n",
       "118  El Salvador has become the first country to ma...                 2458   \n",
       "123                     DO NOT BRAG ABOUT YOUR BITCOIN                  137   \n",
       "124                         Bitcoin to the common man.                  153   \n",
       "127           Bitcoin the HERO we never knew we needed                   69   \n",
       "129    Maybe someone knows who the address belongs to?                   15   \n",
       "131                                     btc purchases                    55   \n",
       "134  Blackrock ETF/Bitcoin will destroy the (new) c...                   29   \n",
       "138           Debunking the Myth of Bitcoin's Use Case                   33   \n",
       "140  An AI-powered Twitter bot predicts Bitcoin’s p...                   24   \n",
       "143                                What do you think?                    52   \n",
       "144           Bitcoin Bank - Safely store your bitcoin                  114   \n",
       "147                                Hodling or selling?                  108   \n",
       "150                             Excessive Bitcoin fees                  111   \n",
       "151  A Personal Computer Mined How Many Bitcoin Per...                   33   \n",
       "\n",
       "    talk_subject_views        date  \n",
       "0               182347  2024-04-14  \n",
       "5                   17  2024-04-14  \n",
       "13                  43  2024-04-14  \n",
       "14                  23  2024-04-14  \n",
       "15                 290  2024-04-14  \n",
       "16                 544  2024-04-14  \n",
       "35                 212  2024-04-14  \n",
       "48                   6  2024-04-14  \n",
       "50                  92  2024-04-14  \n",
       "81                 264  2024-04-14  \n",
       "104                461  2024-04-14  \n",
       "107                235  2024-04-14  \n",
       "110                155  2024-04-14  \n",
       "114              12636  2024-04-14  \n",
       "118              33941  2024-04-14  \n",
       "123               1043  2024-04-14  \n",
       "124                867  2024-04-14  \n",
       "127                402  2024-04-14  \n",
       "129                251  2024-04-14  \n",
       "131                325  2024-04-14  \n",
       "134                237  2024-04-14  \n",
       "138                260  2024-04-14  \n",
       "140                248  2024-04-14  \n",
       "143                390  2024-04-14  \n",
       "144               1065  2024-04-14  \n",
       "147                696  2024-04-14  \n",
       "150               1103  2024-04-14  \n",
       "151                327  2024-04-14  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a1b471",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from textblob import TextBlob\n",
    "import re\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "import nltk\n",
    "\n",
    "def sentiment_polarity(text):\n",
    "    if pd.isna(text):\n",
    "        return 0.0\n",
    "    return TextBlob(text).sentiment.polarity\n",
    "\n",
    "def sentiment_subjectivity(text):\n",
    "    if pd.isna(text):\n",
    "        return 0.5\n",
    "    return TextBlob(text).sentiment.subjectivity\n",
    "    \n",
    "new_column_names = {\n",
    "    'subject': 'talk_subject_id',\n",
    "    'replies': 'talk_subject_replies',\n",
    "    'views': 'talk_subject_views',\n",
    "}\n",
    "\n",
    "# 重命名列\n",
    "df_subject = df_subject.rename(columns=new_column_names)\n",
    "current_date = datetime.now().strftime('%Y-%m-%d')\n",
    "df_subject['date'] = current_date\n",
    "df_subject['talk_subject_emotion'] = df_subject['talk_subject_id'].apply(sentiment_polarity)\n",
    "df_subject['talk_subject_subjectivity'] = df_subject['talk_subject_id'].apply(sentiment_subjectivity)\n",
    "\n",
    "# Replacement mappings\n",
    "replacements = {\n",
    "    r'\\bthats\\b': 'that is',\n",
    "    r'\\bive\\b': 'i have',\n",
    "    r'\\bim\\b': 'i am',\n",
    "    r'\\bya\\b': 'yeah',\n",
    "    r'\\bcant\\b': 'can not',\n",
    "    r'\\bwont\\b': 'will not',\n",
    "    r'\\bid\\b': 'i would',\n",
    "    r'wtf': 'what the fuck',\n",
    "    r'\\bwth\\b': 'what the hell',\n",
    "    r'\\br\\b': 'are',\n",
    "    r'\\bu\\b': 'you',\n",
    "    r'\\bk\\b': 'ok',\n",
    "    r'\\bsux\\b': 'sucks',\n",
    "    r'\\bno+\\b': 'no',\n",
    "    r'\\bcoo+\\b': 'cool',\n",
    "    r'\\bath\\b': 'all time high',\n",
    "    r'\\batl\\b': 'all time low',\n",
    "    r'\\bbtfd\\b': 'buy the fucking dip',\n",
    "    r'\\bico\\b': 'initial coin offering',\n",
    "    r'\\bfomo\\b': 'fear of missing out',\n",
    "    r'\\bfud\\b': 'fear uncertainty doubt',\n",
    "    r'\\bfucking\\b': 'fuck',\n",
    "    r'\\bfudster\\b': 'fear uncertainty doubt spreader',\n",
    "    r'\\broi\\b': 'return on investment',\n",
    "    r'\\bmacd\\b': 'moving average convergence divergence',\n",
    "    r'\\bpoa\\b': 'proof of authority',\n",
    "    r'\\bpow\\b': 'proof of work'\n",
    "}\n",
    "\n",
    "# Function to replace text according to the replacement dictionary\n",
    "def replace_lingo(text):\n",
    "    for pattern, replacement in replacements.items():\n",
    "        text = re.sub(pattern, replacement, text, flags=re.IGNORECASE)\n",
    "    return text\n",
    "\n",
    "# Function to remove URLs\n",
    "def remove_urls(text):\n",
    "    return re.sub(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+|stratum[+]tcp?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', '', text)\n",
    "\n",
    "# Function to strip non-ASCII characters\n",
    "def strip_non_ascii(string):\n",
    "    return ''.join(c for c in string if 0 < ord(c) < 127)\n",
    "\n",
    "# Applying the cleaning functions\n",
    "df_comment['clean_comment'] = df_comment['comment'].str.lower()\n",
    "df_comment['clean_comment'] = df_comment['clean_comment'].apply(remove_urls)\n",
    "df_comment['clean_comment'] = df_comment['clean_comment'].apply(replace_lingo)\n",
    "df_comment['clean_comment'] = df_comment['clean_comment'].apply(strip_non_ascii)\n",
    "\n",
    "# Initialize NLTK's sentiment analyzer\n",
    "nltk.download('vader_lexicon')\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Define a function for sentiment analysis\n",
    "def sentiment_analysis(text):\n",
    "    return analyzer.polarity_scores(text)['compound']\n",
    "\n",
    "# Apply sentiment analysis\n",
    "\n",
    "df_comment['talk_comment_emotion'] = df_comment['clean_comment'].apply(sentiment_analysis)\n",
    "df_comment.drop('clean_comment', axis=1, inplace=True)\n",
    "new_column_names = {\n",
    "    'subject': 'talk_subject_id',\n",
    "    'comment': 'talk_comment',\n",
    "    'user': 'talk_user_id',\n",
    "}\n",
    "df_comment['date'] = current_date\n",
    "df_comment = df_comment.reset_index()\n",
    "df_comment['talk_comment_id'] = df_comment['index']\n",
    "df_comment.drop('index', axis=1, inplace=True)\n",
    "df_comment = df_comment.rename(columns=new_column_names)\n",
    "\n",
    "new_column_names = {\n",
    "    'user': 'talk_user_id',\n",
    "    'activity': 'talk_user_activity',\n",
    "    'merit': 'talk_user_merit',\n",
    "}\n",
    "df_user = df_user.rename(columns=new_column_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5f13e96d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "106"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_subject.to_sql('ods_talk_subjects_delta',engine,chunksize=10000,if_exists=\"replace\",index=False)\n",
    "df_comment.to_sql('ods_talk_comments_delta',engine,chunksize=10000,if_exists=\"replace\",index=False)\n",
    "df_user.to_sql('ods_talk_users_delta',engine,chunksize=10000,if_exists=\"replace\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
